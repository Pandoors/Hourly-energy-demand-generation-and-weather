{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv('weather_features.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# only use data from Madrid\n",
    "weather_data = weather_data[weather_data['city_name']=='Madrid']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weather_data.index = pd.to_datetime(weather_data['dt_iso'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#drop columns that are not needed, rain , snow, clouds, wind direction are not needed\n",
    "weather_data.drop(columns=['dt_iso', 'city_name', 'rain_1h', 'rain_3h', 'snow_3h', 'clouds_all', 'wind_deg'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for categorical columns show value counts\n",
    "for col in weather_data.columns:\n",
    "    if weather_data[col].dtype == 'object':\n",
    "        print(col, weather_data[col].nunique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# since weather_description and weather_icon have a lot of unique values, drop them\n",
    "weather_data.drop(columns=['weather_icon', 'weather_description', 'weather_id'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "energy_data = pd.read_csv('energy_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "energy_data.index = pd.to_datetime(energy_data['time'])\n",
    "# drop columns that are not needed\n",
    "energy_data.drop(columns=['time', \"generation hydro pumped storage aggregated\", \"forecast wind offshore eday ahead\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "energy_data.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sum all the generation types to get the total generation\n",
    "energy_data['total_generation'] = energy_data[energy_data.columns[:20]].sum(axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop all the generation types\n",
    "energy_data.drop(columns=energy_data.columns[:20], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop all the forecast columns\n",
    "forecast_columns = [col for col in energy_data.columns if 'forecast' in col]\n",
    "energy_data.drop(columns=forecast_columns, inplace=True)\n",
    "energy_data.drop(columns=['price day ahead'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_data = pd.merge(energy_data, weather_data, how='inner', left_index=True, right_index=True)\n",
    "merged_data.index = pd.to_datetime(merged_data.index, utc=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns_scale_std = [\"total load actual\", \"price actual\", \"total_generation\", 'temp', 'temp_min', 'temp_max']\n",
    "columns_scale_min_max = ['pressure', 'humidity', 'wind_speed']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_data[columns_scale_std] = (merged_data[columns_scale_std] - merged_data[columns_scale_std].mean()) / merged_data[columns_scale_std].std()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_data[columns_scale_min_max] = (merged_data[columns_scale_min_max] - merged_data[columns_scale_min_max].min()) / (merged_data[columns_scale_min_max].max() - merged_data[columns_scale_min_max].min())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get dummy variables for weather_main\n",
    "merged_data = pd.get_dummies(merged_data, columns=['weather_main'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# add time features\n",
    "merged_data['hour'] = merged_data.index.hour\n",
    "merged_data['day_of_week'] = merged_data.index.dayofweek\n",
    "merged_data['day_of_month'] = merged_data.index.day\n",
    "merged_data['month'] = merged_data.index.month\n",
    "merged_data['day_of_year'] = merged_data.index.year"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get time encodings, as sine and cosine\n",
    "merged_data['hour_sin'] = np.sin(merged_data['hour']*(2.*np.pi/24))\n",
    "merged_data['hour_cos'] = np.cos(merged_data['hour']*(2.*np.pi/24))\n",
    "merged_data['day_of_week_sin'] = np.sin(merged_data['day_of_week']*(2.*np.pi/7))\n",
    "merged_data['day_of_week_cos'] = np.cos(merged_data['day_of_week']*(2.*np.pi/7))\n",
    "merged_data['day_of_month_sin'] = np.sin(merged_data['day_of_month']*(2.*np.pi/30))\n",
    "merged_data['day_of_month_cos'] = np.cos(merged_data['day_of_month']*(2.*np.pi/30))\n",
    "merged_data['month_sin'] = np.sin((merged_data['month']-1)*(2.*np.pi/12))\n",
    "merged_data['month_cos'] = np.cos((merged_data['month']-1)*(2.*np.pi/12))\n",
    "merged_data['day_of_year_sin'] = np.sin((merged_data['day_of_year']-1)*(2.*np.pi/365))\n",
    "merged_data['day_of_year_cos'] = np.cos((merged_data['day_of_year']-1)*(2.*np.pi/365))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_data.drop(columns=['hour', 'day_of_week', 'day_of_month', 'month', 'day_of_year'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_data.to_csv('merged_data.csv', index_label='time')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# example use\n",
    "merged_data = pd.read_csv('merged_data.csv', index_col='time')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
